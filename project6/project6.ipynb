{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import glob\n",
    "import configparser\n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "from pyspark.sql.types import IntegerType, BooleanType, DateType, LongType, StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Declare common variable\n",
    "\n",
    "US_CITY_DEMOGRAPHICS_SOURCE_FILE_PATH = 'us-cities-demographics.csv'\n",
    "I94_DICTIONARY_SOURCE_FILE_PATH ='I94_SAS_Labels_Descriptions.SAS'\n",
    "\n",
    "\n",
    "GARTHERED_DATA_PATH = 'garthered_data/'\n",
    "GARTHERED_IMMIGRATION_DATA_PATH = GARTHERED_DATA_PATH + 'immigration/'\n",
    "GARTHERED_US_CITY_DEMOGRAPHICS_DATA_PATH = GARTHERED_DATA_PATH + \"us_cities_demogarphics.parquet\"\n",
    "GARTHERED_I94_COUNTRY_DATA_PATH = GARTHERED_DATA_PATH + \"i94_country.parquet\"\n",
    "GARTHERED_I94_AIRPORT_DATA_PATH = GARTHERED_DATA_PATH + \"i94_airport.parquet\"\n",
    "GARTHERED_I94_IMMIGRATION_MODE_DATA_PATH = GARTHERED_DATA_PATH + \"i94_immigration_mode.parquet\"\n",
    "GARTHERED_I94_US_STATE_DATA_PATH = GARTHERED_DATA_PATH + \"i94_us_state.parquet\"\n",
    "GARTHERED_I94_VISA_TYPE_DATA_PATH = GARTHERED_DATA_PATH + \"i94_visa_type.parquet\"\n",
    "\n",
    "\n",
    "OUTPUT_DATA = 'output_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Init SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create function to transelate to timestampe\n",
    "@udf(T.TimestampType())\n",
    "def to_timestamp (d):\n",
    "    if d:\n",
    "        return (datetime(1960,1,1) + timedelta(days=int(d)))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- immigration\n",
    "- us-cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.1 Garther immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define get list file from directory and extension\n",
    "\n",
    "def get_files(filepath, ext):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root, ext))\n",
    "        for f in files :\n",
    "            all_files.append((os.path.abspath(f), os.path.basename(f)))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get list source files for immigration\n",
    "\n",
    "list_source_i94_immigration_file_path = get_files('../../data/18-83510-I94-Data-2016', '*.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Garther all data from source folder and write them to parquet files\n",
    "\n",
    "for file_path in list_source_i94_immigration_file_path:\n",
    "    df_spark = spark.read.format('com.github.saurfang.sas.spark').load(file_path[0])\n",
    "    df_spark.write.option(\"header\", True) \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(f\"{GARTHERED_IMMIGRATION_DATA_PATH}/{file_path[1]}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2 Garther US city demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_city_demographics_raw_df_spark = spark.read.csv(US_CITY_DEMOGRAPHICS_SOURCE_FILE_PATH, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write it to parquet file\n",
    "\n",
    "us_city_demographics_raw_df_spark \\\n",
    "    .withColumnRenamed(\"Median Age\", \"median_age\") \\\n",
    "    .withColumnRenamed(\"Male Population\", \"male_population\") \\\n",
    "    .withColumnRenamed(\"Female Population\", \"female_population\") \\\n",
    "    .withColumnRenamed(\"Total Population\", \"total_population\") \\\n",
    "    .withColumnRenamed(\"Number of Veterans\", \"number_of_veterans\") \\\n",
    "    .withColumnRenamed(\"Average Household Size\", \"average_household_size\") \\\n",
    "    .withColumnRenamed(\"State Code\", \"state_code\") \\\n",
    "    .write.option(\"header\", True) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(GARTHERED_US_CITY_DEMOGRAPHICS_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.3 Garther countries from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_dictionary_lines = open(I94_DICTIONARY_SOURCE_FILE_PATH, 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_country_raw_df_spark = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        [re.search(r\"^\\s*(\\S+)\\s*=\\s*'\\s*(\\S.*\\S)\\s*'.*$\", line).groups() for line in i94_dictionary_lines[9:298]],\n",
    "        columns=['country_code', 'country_name']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write it to parquet file\n",
    "\n",
    "i94_country_raw_df_spark.write.mode(\"overwrite\").parquet(GARTHERED_I94_COUNTRY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.4 Garther I94 airports from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_airport_raw_df_spark = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        [re.search(r\"^\\s*'\\s*(\\S+)\\s*'\\s*=\\s*'\\s*(\\S.*\\S)\\s*'.*$\", line).groups() for line in i94_dictionary_lines[302:962]],\n",
    "        columns=['airport_code', 'airport_name']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write it to parquet file\n",
    "\n",
    "i94_airport_raw_df_spark.write.mode(\"overwrite\").parquet(GARTHERED_I94_AIRPORT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.5 Garther modes from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_immigration_mode_raw_df_spark = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        [re.search(r\"^\\s*(\\S+)\\s*=\\s*'\\s*(\\S.*\\S)\\s*'.*$\", line).groups() for line in i94_dictionary_lines[972:976]],\n",
    "        columns=['mode_code', 'mode_name']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write it to parquet file\n",
    "\n",
    "i94_immigration_mode_raw_df_spark.write.mode(\"overwrite\").parquet(GARTHERED_I94_IMMIGRATION_MODE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.6 Garther us-states from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_us_state_raw_df_spark = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        [re.search(r\"^\\s*'(\\S+)'\\s*=\\s*'\\s*(\\S.*\\S)\\s*'.*$\", line).groups() for line in i94_dictionary_lines[981:1036]],\n",
    "        columns=['state_code', 'state_name']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write it to parquet file\n",
    "\n",
    "i94_us_state_raw_df_spark.write.mode(\"overwrite\").parquet(GARTHERED_I94_US_STATE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.7 Garther visa from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_visa_type_raw_df_spark = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        [re.search(r\"^\\s*(\\S+)\\s*=\\s*(\\S.*\\S).*$\", line).groups() for line in i94_dictionary_lines[1046:1049]],\n",
    "        columns=['visa_code', 'visa_type']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write it to parquet file\n",
    "\n",
    "i94_visa_type_raw_df_spark.write.mode(\"overwrite\").parquet(GARTHERED_I94_VISA_TYPE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 2: Explore and Assess the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.1. The I94 immigration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1) Load data to spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load immigration data\n",
    "\n",
    "immigration_df_spark = spark.read.option(\"mergeSchema\", \"true\").parquet(f\"{GARTHERED_IMMIGRATION_DATA_PATH}/*r16_sub.sas7bdat.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+--------+-----------+-----------+----------+-----------+-------------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|validres|delete_days|delete_mexl|delete_dup|delete_visa|delete_recdup|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+--------+-----------+-----------+----------+-----------+-------------+\n",
      "|5680949.0|2016.0|   7.0| 117.0| 117.0|    NYC|20659.0|    1.0|     NY|   null|  30.0|    3.0|  1.0|20160724|     NPL| null|      G|   null|   null|   null| 1986.0|     D/S|     F|  null|     IG|2.947450085E9| 3940|      F1|    null|       null|       null|      null|       null|         null|\n",
      "|5680950.0|2016.0|   7.0| 245.0| 245.0|    DET|20659.0|    1.0|     IL|20679.0|  46.0|    2.0|  1.0|20160813|    null| null|      G|      O|   null|      M| 1970.0|01232017|     M| 78652|     DL|2.947451085E9|  188|      B2|    null|       null|       null|      null|       null|         null|\n",
      "|5680953.0|2016.0|   7.0| 245.0| 245.0|    SEA|20659.0|    1.0|     WA|20670.0|  36.0|    2.0|  1.0|20160804|    null| null|      G|      O|   null|      M| 1980.0|01232017|     F|130660|     OZ|2.947454785E9|  272|      B2|    null|       null|       null|      null|       null|         null|\n",
      "|5680954.0|2016.0|   7.0| 135.0| 135.0|    ORL|20659.0|    1.0|     FL|20673.0|  17.0|    2.0|  1.0|20160808|    null| null|      O|      O|   null|      M| 1999.0|10212016|     F|294090|     MT|2.947455685E9|  176|      WT|    null|       null|       null|      null|       null|         null|\n",
      "|5680956.0|2016.0|   7.0| 213.0| 213.0|    MIA|20659.0|    1.0|     FL|20728.0|  23.0|    2.0|  1.0|20160724|     HYD| null|      G|      O|   null|      M| 1993.0|01232017|     M| 21180|     QR|2.947457485E9|  777|      B2|    null|       null|       null|      null|       null|         null|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+--------+-----------+-----------+----------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2) Standardize data type\n",
    "\n",
    "Cast data for these columns:\n",
    "\n",
    " - cicid: long\n",
    " - i94yr: integer\n",
    " - i94mon: integer\n",
    " - i94cit: integer\n",
    " - i94res: integer\n",
    " - arrdate: timestamp\n",
    " - i94mode: integer\n",
    " - i94addr: string\n",
    " - depdate: timestamp\n",
    " - i94bir: integer\n",
    " - i94visa: integer\n",
    " - biryear: integer\n",
    " - admnum: long\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_standardize_df_spark = immigration_df_spark\\\n",
    "                                    .withColumn(\"cicid\", col(\"cicid\").cast(LongType())) \\\n",
    "                                    .withColumn(\"i94yr\", col(\"i94yr\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"i94mon\", col(\"i94mon\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"i94cit\", col(\"i94cit\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"i94res\", col(\"i94res\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"arrdate\", to_timestamp(\"arrdate\")) \\\n",
    "                                    .withColumn(\"i94mode\", col(\"i94mode\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"depdate\", to_timestamp(\"depdate\")) \\\n",
    "                                    .withColumn(\"i94bir\", col(\"i94bir\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"i94visa\", col(\"i94visa\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"biryear\", col(\"biryear\").cast(IntegerType())) \\\n",
    "                                    .withColumn(\"admnum\", col(\"admnum\").cast(LongType())) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: long (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: timestamp (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: timestamp (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: long (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_standardize_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+------+------+-------+-------------------+-------+-------+-------------------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+----------+-----+--------+--------+-----------+-----------+----------+-----------+-------------+\n",
      "|  cicid|i94yr|i94mon|i94cit|i94res|i94port|            arrdate|i94mode|i94addr|            depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|    admnum|fltno|visatype|validres|delete_days|delete_mexl|delete_dup|delete_visa|delete_recdup|\n",
      "+-------+-----+------+------+------+-------+-------------------+-------+-------+-------------------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+----------+-----+--------+--------+-----------+-----------+----------+-----------+-------------+\n",
      "|5680949| 2016|     7|   117|   117|    NYC|2016-07-24 00:00:00|      1|     NY|               null|    30|      3|  1.0|20160724|     NPL| null|      G|   null|   null|   null|   1986|     D/S|     F|  null|     IG|2947450085| 3940|      F1|    null|       null|       null|      null|       null|         null|\n",
      "|5680950| 2016|     7|   245|   245|    DET|2016-07-24 00:00:00|      1|     IL|2016-08-13 00:00:00|    46|      2|  1.0|20160813|    null| null|      G|      O|   null|      M|   1970|01232017|     M| 78652|     DL|2947451085|  188|      B2|    null|       null|       null|      null|       null|         null|\n",
      "|5680953| 2016|     7|   245|   245|    SEA|2016-07-24 00:00:00|      1|     WA|2016-08-04 00:00:00|    36|      2|  1.0|20160804|    null| null|      G|      O|   null|      M|   1980|01232017|     F|130660|     OZ|2947454785|  272|      B2|    null|       null|       null|      null|       null|         null|\n",
      "|5680954| 2016|     7|   135|   135|    ORL|2016-07-24 00:00:00|      1|     FL|2016-08-07 00:00:00|    17|      2|  1.0|20160808|    null| null|      O|      O|   null|      M|   1999|10212016|     F|294090|     MT|2947455685|  176|      WT|    null|       null|       null|      null|       null|         null|\n",
      "|5680956| 2016|     7|   213|   213|    MIA|2016-07-24 00:00:00|      1|     FL|2016-10-01 00:00:00|    23|      2|  1.0|20160724|     HYD| null|      G|      O|   null|      M|   1993|01232017|     M| 21180|     QR|2947457485|  777|      B2|    null|       null|       null|      null|       null|         null|\n",
      "+-------+-----+------+------+------+-------+-------------------+-------+-------+-------------------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+----------+-----+--------+--------+-----------+-----------+----------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show example data\n",
    "\n",
    "immigration_standardize_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3) Clean for null, empty data, and drop duplicate data\n",
    "\n",
    "- Drop the rows where these column is null or empty\n",
    "\n",
    "[ 'i94cit', 'i94port', 'i94res', 'i94addr', 'i94mode ]\n",
    "\n",
    "\n",
    "- And drop duplicate data when these column was duplicate:\n",
    "\n",
    "[\"cicid\", \"admnum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_df_spark_clean = immigration_standardize_df_spark\\\n",
    "                                .dropna(subset=['i94cit', 'i94port', 'i94res', 'i94addr', 'i94mode'])\\\n",
    "                                .dropDuplicates(subset=[\"cicid\", \"admnum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------------------+-------+-------+-------------------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-----------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|            arrdate|i94mode|i94addr|            depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|     admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------------------+-------+-------+-------------------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-----------+-----+--------+\n",
      "|  118| 2016|     4|   103|   103|    NEW|2016-04-01 00:00:00|      1|     MD|2016-04-05 00:00:00|    53|      2|  1.0|20160401|    null| null|      G|      O|   null|      M|   1963|06292016|     F|  null|     LH|55436239033|00402|      WT|\n",
      "|  120| 2016|     4|   103|   103|    NEW|2016-04-01 00:00:00|      1|     NJ|2016-04-17 00:00:00|    27|      2|  1.0|20160401|    null| null|      G|      K|   null|      M|   1989|06292016|     M|  null|     OS|55421884033|00089|      WT|\n",
      "|  146| 2016|     4|   103|   103|    NEW|2016-04-01 00:00:00|      1|     NY|2016-04-08 00:00:00|    23|      2|  1.0|20160401|    null| null|      G|      O|   null|      M|   1993|06292016|     M|  null|     OS|55422493633|00089|      WT|\n",
      "|  229| 2016|     3|   103|   103|    NYC|2016-03-01 00:00:00|      1|     NY|2016-03-03 00:00:00|    21|      2|  1.0|20160301|    null| null|      O|      O|   null|      M|   1995|05292016|  null|  null|     CM|53655241933|00830|      WT|\n",
      "|  296| 2016|     4|   103|   103|    NYC|2016-04-01 00:00:00|      1|     NY|2016-04-04 00:00:00|    29|      2|  1.0|20160401|    null| null|      O|      O|   null|      M|   1987|06292016|  null|  null|     AB|55440071633|07248|      WT|\n",
      "+-----+-----+------+------+------+-------+-------------------+-------+-------+-------------------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-----------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df_spark_clean.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.2. The US city demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1) Load data for spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "us_cities_demographics_df_spark = spark.read.option(\"mergeSchema\", \"true\").parquet(GARTHERED_US_CITY_DEMOGRAPHICS_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- average_household_size: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_cities_demographics_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|median_age|male_population|female_population|total_population|number_of_veterans|Foreign-born|average_household_size|state_code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show a example data\n",
    "\n",
    "us_cities_demographics_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2) Standardize column by change the column name to standard\n",
    "\n",
    "Change these columns flowing to snake case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities_demographics_standardize_df_spark = us_cities_demographics_df_spark\\\n",
    "                                                .withColumnRenamed(\"City\", \"city\") \\\n",
    "                                                .withColumnRenamed(\"State\", \"state\") \\\n",
    "                                                .withColumnRenamed(\"Median Age\", \"median_age\") \\\n",
    "                                                .withColumnRenamed(\"Male Population\", \"male_population\") \\\n",
    "                                                .withColumnRenamed(\"Female Population\", \"female_population\") \\\n",
    "                                                .withColumnRenamed(\"Total Population\", \"total_population\") \\\n",
    "                                                .withColumnRenamed(\"Number of Veterans\", \"number_of_neterans\") \\\n",
    "                                                .withColumnRenamed(\"Foreign-born\", \"foreign_born\") \\\n",
    "                                                .withColumnRenamed(\"Average Household Size\", \"average_household_size\") \\\n",
    "                                                .withColumnRenamed(\"State Code\", \"state_code\") \\\n",
    "                                                .withColumnRenamed(\"Race\", \"race\") \\\n",
    "                                                .withColumnRenamed(\"Count\", \"count\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_veterans: string (nullable = true)\n",
      " |-- foreign_born: string (nullable = true)\n",
      " |-- average_household_size: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_cities_demographics_standardize_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.3. The I94 countries data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The I94 contries data is dictionary data so dose not need to standardize and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data to spark dataframe\n",
    "\n",
    "i94_country_df_spark = spark.read.option(\"mergeSchema\", \"true\").parquet(GARTHERED_I94_COUNTRY_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_country_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|country_code|        country_name|\n",
      "+------------+--------------------+\n",
      "|         582|MEXICO Air Sea, a...|\n",
      "|         236|         AFGHANISTAN|\n",
      "|         101|             ALBANIA|\n",
      "|         316|             ALGERIA|\n",
      "|         102|             ANDORRA|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_country_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.4. The I94 Airport data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The I94 airport data is dictionary data so dose not need to standardize and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load airport data to spark dataframe\n",
    "\n",
    "i94_airport_df_spark = spark.read.option(\"mergeSchema\", \"true\").parquet(GARTHERED_I94_AIRPORT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airport_code: string (nullable = true)\n",
      " |-- airport_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_airport_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|airport_code|        airport_name|\n",
      "+------------+--------------------+\n",
      "|         ALC|           ALCAN, AK|\n",
      "|         ANC|       ANCHORAGE, AK|\n",
      "|         BAR|BAKER AAF - BAKER...|\n",
      "|         DAC|   DALTONS CACHE, AK|\n",
      "|         PIZ|DEW STATION PT LA...|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_airport_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.5. The I94 Immigration Mode data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The I94 Immigration Mode data is dictionary data so dose not need to standardize and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data to spark dataframe\n",
    "\n",
    "i94_immigration_mode_df_spark = spark.read.option(\"mergeSchema\", \"true\").parquet(GARTHERED_I94_IMMIGRATION_MODE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mode_code: string (nullable = true)\n",
      " |-- mode_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration_mode_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|mode_code|   mode_name|\n",
      "+---------+------------+\n",
      "|        1|         Air|\n",
      "|        2|         Sea|\n",
      "|        3|        Land|\n",
      "|        9|Not reported|\n",
      "+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration_mode_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.6. The I94 US state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The I94 US state data is dictionary data so dose not need to standardize and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data to dataframe\n",
    "\n",
    "i94_us_state_df_spark = spark.read.option(\"mergeSchema\", \"true\").parquet(GARTHERED_I94_US_STATE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_us_state_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|state_code|state_name|\n",
      "+----------+----------+\n",
      "|        AL|   ALABAMA|\n",
      "|        AK|    ALASKA|\n",
      "|        AZ|   ARIZONA|\n",
      "|        AR|  ARKANSAS|\n",
      "|        CA|CALIFORNIA|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_us_state_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.7. The I94 Visa Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The I94 visa type data is dictionary data so dose not need to standardize and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data to dataframe\n",
    "\n",
    "i94_visa_type_df_spark = spark.read.option(\"mergeSchema\", \"true\").parquet(GARTHERED_I94_VISA_TYPE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- visa_code: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_visa_type_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|visa_code|visa_type|\n",
      "+---------+---------+\n",
      "|        1| Business|\n",
      "|        2| Pleasure|\n",
      "|        3|  Student|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_visa_type_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 3: Define the Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3.1 Conceptual Data Model\n",
    "\n",
    "I have developed a set of Fact and Dimension tables as a Star Schema for these reasons:\n",
    "    - It can be used by Data Analysts and other relevant business professionals to gain deeper insight into various immigration figures, trends and statistics recorded historically.\n",
    "    - Based on the simple relationships between fact and dimensions, development is free to invent creative queries to extract untold insights about the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![conceptual data model](./images/conceptual-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "- Garther the data from source data\n",
    "- Load the data into spark dataframe\n",
    "- Create Fact tables\n",
    "- Create Dimension tables\n",
    "- Write data into parquet files\n",
    "\n",
    "\n",
    "Fact table:\n",
    "\n",
    "- immigration_fact\n",
    "\n",
    "Dimension tables:\n",
    "\n",
    "- us_state_demographics_dim\n",
    "- country_dim\n",
    "- airport_dim\n",
    "- immigration_mode_dim\n",
    "- us_state_dim\n",
    "- visa_type_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Step 4: Run Pipelines to Model the Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.1 Create the data model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1) Build fact immigartion table\n",
    "\n",
    "Build fact immigartion data by select these column useful for table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create view for immigration table\n",
    "\n",
    "immigration_df_spark_clean.createOrReplaceTempView(\"immigration_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select the columns useful for data immigration\n",
    "\n",
    "immigration_fact_table = spark.sql(\"\"\"\n",
    "        SELECT  DISTINCT cicid,\n",
    "                         i94yr   AS year,\n",
    "                         i94mon  AS month,\n",
    "                         i94cit  AS country_code,\n",
    "                         i94res  AS residence,\n",
    "                         i94port AS airport_code,\n",
    "                         arrdate AS arrival_date,\n",
    "                         i94mode AS mode_code, \n",
    "                         i94addr AS state_code,\n",
    "                         depdate AS departure_date,\n",
    "                         i94bir  AS age,\n",
    "                         i94visa AS visa_code,\n",
    "                         biryear AS birth_year,\n",
    "                         gender  AS gender,\n",
    "                         airline AS airline,\n",
    "                         admnum  AS admission_number,\n",
    "                         fltno   AS flight_number\n",
    "        FROM immigration_view\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Final schema for fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: long (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- residence: integer (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- airport_code: string (nullable = true)\n",
      " |-- arrival_date: timestamp (nullable = true)\n",
      " |-- mode_code: integer (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- departure_date: timestamp (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa_code: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admission_number: long (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_fact_table.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " - Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+------------+---------+---------+------------+-------------------+---------+----------+-------------------+---+---------+----------+------+-------+----------------+-------------+\n",
      "| cicid|year|month|country_code|residence|city_code|airport_code|       arrival_date|mode_code|state_code|     departure_date|age|visa_code|birth_year|gender|airline|admission_number|flight_number|\n",
      "+------+----+-----+------------+---------+---------+------------+-------------------+---------+----------+-------------------+---+---------+----------+------+-------+----------------+-------------+\n",
      "| 39577|2016|    3|         209|      209|      HHW|         HHW|2016-03-01 00:00:00|        1|        HI|2016-03-05 00:00:00| 20|        2|      1996|     M|     JL|     53655815733|        00786|\n",
      "| 42195|2016|    4|         135|      135|      TAM|         TAM|2016-04-01 00:00:00|        1|        FL|2016-04-16 00:00:00| 80|        2|      1936|     F|     BA|     55443641033|        02167|\n",
      "|206889|2016|    3|         213|      213|      ORL|         ORL|2016-03-02 00:00:00|        1|        FL|2016-03-14 00:00:00| 37|        1|      1979|  null|     EK|     89516094330|        00219|\n",
      "|330787|2016|    3|         111|      111|      NYC|         NYC|2016-03-03 00:00:00|        1|        TN|2016-03-08 00:00:00| 37|        2|      1979|     F|     AA|     53745119133|        00045|\n",
      "|479216|2016|    4|         148|      112|      NYC|         NYC|2016-04-03 00:00:00|        1|        NY|2016-04-10 00:00:00| 52|        2|      1964|     M|     LH|     55552696033|        00410|\n",
      "+------+----+-----+------------+---------+---------+------------+-------------------+---------+----------+-------------------+---+---------+----------+------+-------+----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_fact_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- write fact immigration table as parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fact_table_path = OUTPUT_DATA + \"immigration_fact_table.parquet\"\n",
    "immigration_fact_table.write.mode(\"overwrite\").parquet(immigration_fact_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2) Build dimension us-state demographics table\n",
    "\n",
    "Build dimension us-state demographics table by using the us-city demographics source data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Final Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_veterans: string (nullable = true)\n",
      " |-- foreign_born: string (nullable = true)\n",
      " |-- average_household_size: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "us_cities_demographics_standardize_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            city|        state|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|                race|count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_cities_demographics_standardize_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- write dimesion city_demographics table as parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_state_demographics_dim_table_path = OUTPUT_DATA + \"us_state_demographics_dim_table.parquet\"\n",
    "us_cities_demographics_standardize_df_spark.write.mode(\"overwrite\").parquet(us_state_demographics_dim_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3) Build dimension country table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Final schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_country_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|country_code|        country_name|\n",
      "+------------+--------------------+\n",
      "|         582|MEXICO Air Sea, a...|\n",
      "|         236|         AFGHANISTAN|\n",
      "|         101|             ALBANIA|\n",
      "|         316|             ALGERIA|\n",
      "|         102|             ANDORRA|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_country_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- write dimesion country table as parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_dim_table_path = OUTPUT_DATA + \"country_dim_table.parquet\"\n",
    "i94_country_df_spark.write.mode(\"overwrite\").parquet(country_dim_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4) Build dimension airport table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Final schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airport_code: string (nullable = true)\n",
      " |-- airport_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_airport_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|airport_code|        airport_name|\n",
      "+------------+--------------------+\n",
      "|         ALC|           ALCAN, AK|\n",
      "|         ANC|       ANCHORAGE, AK|\n",
      "|         BAR|BAKER AAF - BAKER...|\n",
      "|         DAC|   DALTONS CACHE, AK|\n",
      "|         PIZ|DEW STATION PT LA...|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_airport_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- write dimesion airport table as parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_dim_table_path = OUTPUT_DATA + \"airport_dim_table.parquet\"\n",
    "i94_airport_df_spark.write.mode(\"overwrite\").parquet(airport_dim_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 5) Build dimension immigration mode table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Final schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mode_code: string (nullable = true)\n",
      " |-- mode_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration_mode_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|mode_code|   mode_name|\n",
      "+---------+------------+\n",
      "|        1|         Air|\n",
      "|        2|         Sea|\n",
      "|        3|        Land|\n",
      "|        9|Not reported|\n",
      "+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_immigration_mode_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- write dimesion immigration mode table as parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_mode_dim_table_path = OUTPUT_DATA + \"immigration_mode_dim_table.parquet\"\n",
    "i94_mode_df_spark.write.mode(\"overwrite\").parquet(immigration_mode_dim_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 6) Build dimension us state table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Final schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_us_state_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|state_code|state_name|\n",
      "+----------+----------+\n",
      "|        AL|   ALABAMA|\n",
      "|        AK|    ALASKA|\n",
      "|        AZ|   ARIZONA|\n",
      "|        AR|  ARKANSAS|\n",
      "|        CA|CALIFORNIA|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_us_state_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- write dimesion us state table as parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_state_dim_table_path = OUTPUT_DATA + \"us_state_dim_table.parquet\"\n",
    "i94_us_state_df_spark.write.mode(\"overwrite\").parquet(us_state_dim_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 7) Build dimension visa type table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Final schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- visa_code: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_visa_type_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|visa_code|visa_type|\n",
      "+---------+---------+\n",
      "|        1| Business|\n",
      "|        2| Pleasure|\n",
      "|        3|  Student|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_visa_type_df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- write dimesion visa type table as parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_type_dim_table_path = OUTPUT_DATA + \"visa_type_dim_table.parquet\"\n",
    "i94_visa_type_df_spark.write.mode(\"overwrite\").parquet(visa_type_dim_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Data Quality Checks\n",
    "\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1) Check existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_existing_data(df, df_name):\n",
    "    \"\"\"\n",
    "    Check data exist or not by dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    if df.count() > 0:\n",
    "        print(f\"Existed data on dataframe: {df_name}.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Not existed data on dataframe: {df_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed data on dataframe: immigration_fact_table.\n",
      "Existed data on dataframe: i94_country_df_spark.\n",
      "Existed data on dataframe: i94_airport_df_spark.\n",
      "Existed data on dataframe: i94_immigration_mode_df_spark.\n",
      "Existed data on dataframe: i94_us_state_df_spark.\n",
      "Existed data on dataframe: i94_visa_type_df_spark.\n"
     ]
    }
   ],
   "source": [
    "list_dataframe_to_check = [\n",
    "    [immigration_fact_table, \"immigration_fact_table\"],\n",
    "    [i94_country_df_spark, \"i94_country_df_spark\"],\n",
    "    [i94_airport_df_spark, \"i94_airport_df_spark\"],\n",
    "    [i94_immigration_mode_df_spark, \"i94_immigration_mode_df_spark\"],\n",
    "    [i94_us_state_df_spark, \"i94_us_state_df_spark\"],\n",
    "    [i94_visa_type_df_spark, \"i94_visa_type_df_spark\"]\n",
    "]\n",
    "\n",
    "for df in list_dataframe_to_check:\n",
    "    check_existing_data(*df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2) Checking relational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check relation between immigration data with visa type\n",
    "\n",
    "immigration_joined = immigration_fact_table.join(i94_visa_type_df_spark, \n",
    "                            (immigration_fact_table.visa_code == i94_visa_type_df_spark.visa_code)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: long (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- residence: integer (nullable = true)\n",
      " |-- airport_code: string (nullable = true)\n",
      " |-- arrival_date: timestamp (nullable = true)\n",
      " |-- mode_code: integer (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- departure_date: timestamp (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa_code: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admission_number: long (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      " |-- visa_code: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "| cicid|visa_type|\n",
      "+------+---------+\n",
      "| 81663| Pleasure|\n",
      "| 83762|  Student|\n",
      "|247835| Pleasure|\n",
      "|267801| Pleasure|\n",
      "|276293| Pleasure|\n",
      "+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_joined.select(col('cicid'), col('visa_type')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
